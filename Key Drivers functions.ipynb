{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "262258d3-5c3e-4e66-be9b-fa6057297ffb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import key libraries\n",
    "import pyspark\n",
    "from pyspark.sql.types import IntegerType, FloatType, DateType\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import date\n",
    "from datetime import datetime as dt\n",
    "import pytz \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge \n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import model_selection \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "def creat_sql(select_site, select_machine):\n",
    "    \"\"\"\n",
    "    Function that create sql that allow users to interact with database\n",
    "    Parameters:\n",
    "    select_site: str - Site name user selected\n",
    "    select_machine: str - Machine name user selected\n",
    "    \"\"\"\n",
    "    # build machine_table \n",
    "    machine_table = '_'.join([select_site,select_machine,'timeseries'])\n",
    "    # build data_table\n",
    "    data_table = '.'.join(['groupdb_famc_energy_analytics',machine_table])\n",
    "    # build sql \n",
    "    sql = 'select * from ' +data_table\n",
    "    return sql\n",
    "\n",
    "def create_widget(name, data, feature, type):\n",
    "    \"\"\"\n",
    "    Function that creates widges in the notebook that allow users interact with the code\n",
    "    Parameters:\n",
    "    name: str - Name desired for the widget\n",
    "    data: pd.DataFrame - dataframe containing the data needed to create the widget\n",
    "    feature: str - name of the column to be used to extract the unique values from data\n",
    "    \"\"\"\n",
    "    items = data[feature].unique()\n",
    "    if type == 'dropdown':\n",
    "        dbutils.widgets.dropdown(name, items[0], [x for x in items])\n",
    "    elif type == 'multiselect':\n",
    "        dbutils.widgets.multiselect(name, items[0], [x for x in items])\n",
    "    else:\n",
    "        print('Widget type not recognized')\n",
    "\n",
    "def historical_data (data, n_months):\n",
    "    \"\"\"\n",
    "    Helper function to get the historical data\n",
    "    Parameters:\n",
    "    data: pd.DataFrame - dataframe containing the data needed to retrieve historical data\n",
    "    n_months: int - Number of months the user can track from historoical data, defaulted to be the last 18 months\n",
    "    \"\"\"\n",
    "    today = date.today()\n",
    "    \n",
    "    #past_date  = today - pd.DateOffset(months=n_months)\n",
    "    past_date  = today - pd.DateOffset(months=n_months)\n",
    "    \n",
    "    data = data[data['time_bucket_local'] >= str(past_date)]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def prod_codes_sorting(data):\n",
    "    \"\"\"\n",
    "    Helper function that sort the prod_codes of one machine by Descending order via number of datapoints\n",
    "    Parameters:\n",
    "    data: pd.DataFrame - dataframe containing the data needed to retrieve prod_codes\n",
    "    \"\"\" \n",
    "    prod_code = data.groupby('prod_code')['time_bucket_local'].count().reset_index().sort_values(by='time_bucket_local',ascending = False)\n",
    "    return prod_code\n",
    "\n",
    "def get_time_series_data (data,select_prod_codes):\n",
    "    \"\"\"\n",
    "    Function that create training data based on the prod_codes that have been selected\n",
    "    Parameters:\n",
    "    data: pd.DataFrame - dataframe containing the data needed to create training data\n",
    "    \"\"\" \n",
    "     # filter to only selected prod_codes\n",
    "    data = data [data['prod_code'].isin(select_prod_codes)] \n",
    "    \n",
    "    # get rid of redundant columns \n",
    "    time_series_data = data.iloc[:,2:]\n",
    "    time_series_data.drop(['machine','time_bucket_utc'],axis = 1,inplace = True)\n",
    "    \n",
    "    return time_series_data   \n",
    "\n",
    "def get_training_data (data,select_prod_codes):\n",
    "    \"\"\"\n",
    "    Function that create training data based on the prod_codes that have been selected\n",
    "    Parameters:\n",
    "    data: pd.DataFrame - dataframe containing the data needed to create training data\n",
    "    select_prod_codes: list - list conatining the select_prod_codes \n",
    "    \"\"\"\n",
    "    # filter to only selected prod_codes\n",
    "    data = data [data['prod_code'].isin(select_prod_codes)] \n",
    "\n",
    "\n",
    "    # get rid of redundant columns     \n",
    "    training_data = data.iloc[:,5:]     \n",
    "    \n",
    "    return training_data  \n",
    "\n",
    "def remove_outlier(df):\n",
    "    df = df.dropna()\n",
    "    # define outlier function for each column \n",
    "    def outliers(df, ft): \n",
    "        \n",
    "        lower_bound = df[ft].quantile(0.05)\n",
    "        upper_bound = df[ft].quantile(0.99)\n",
    "        \n",
    "        ft_index = df.index[(df[ft]<lower_bound)|(df[ft]>upper_bound)]\n",
    "        return ft_index\n",
    "    \n",
    "    remove_index =[]\n",
    "    for col in df.columns:\n",
    "        remove_index.extend(outliers(df, col))\n",
    "        \n",
    "    remove_index=sorted(set(remove_index))    \n",
    "    df = df.drop(remove_index)    \n",
    "    return df \n",
    "\n",
    "# The following section is for auto_visaulizatin DTreeReg_mix_gaussian_splits testing\n",
    "def get_gmm_splits(data, variable):     \n",
    "    \"\"\"\n",
    "    Function that splits the data base on the GMM algo. \n",
    "    Parameters:\n",
    "    data: pd.DataFrame - dataframe containing the data needed to get peaks\n",
    "    variable: str - the variable that for peak detection\n",
    "    \"\"\" \n",
    "        \n",
    "    # extract variable data \n",
    "    data = np.array(data[variable])\n",
    "    # select the best n_numbers, looping from 1 to 3 >> edge case that max(data) == min (data), which means the variable is consant, then the best_n_components is defaluted to be 1 culster only.\n",
    "    #compare with n_components best fit the data, ranging from 1 to 3.\n",
    "    # based on the matric of gmm.bic Bayesian information criterion (BIC):This criterion gives us an estimation on how much is good the GMM in terms of predicting the data we actually have. The lower is the BIC, the better is the model to actually predict the data we have, and by extension, the true, unknown, distribution.\n",
    "\n",
    "    if max (data) == min(data):\n",
    "        best_n_components = 1\n",
    "    else: \n",
    "        gmm_result = []\n",
    "        for n_components in range(1,4):\n",
    "            gmm = GaussianMixture(n_components).fit(data.reshape(-1, 1))\n",
    "            gmm_result.append(gmm.bic(data.reshape(-1, 1)))\n",
    "        best_n_components = gmm_result.index(min(gmm_result))+1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Key Drivers functions",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
